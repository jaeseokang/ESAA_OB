{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1장. 머신 러닝과 딥런이\n",
        "\n",
        "## 1.1 인공지능, 머신 러닝과 딥러닝\n",
        "인공지능(AI)은 인간의 지능을 모방해 사람이 하는 일을 기계가 할 수 있도록 하는 기술\n",
        "구현 방법: 머신 러닝, 딥러닝\n",
        "관계: 인공지능 > 머신 러닝 > 딥러닝\n",
        "\n",
        "머신 러닝 vs 딥러닝\n",
        "1. 머신 러닝: 주어진 데이터를 인간이 먼저 처리(전처리), 범용적인 목적을 위해 제작된 것으로 데이터의 특징을 스스로 추출하지 못함. 이 과정을 인간이 처리해 주어야 하는 것이 머신 러닝. 즉, 머신 러닝 학습 과정은 각 데이터 특성을 컴퓨터에 인식시키고 학습시켜 문제를 해결\n",
        "2. 딥러닝: 인간이 하던 작업을 생략. 대량의 데이터를 신경망에 적용하면 컴퓨터가 스스로 분석한 후 답을 찾음."
      ],
      "metadata": {
        "id": "vKswwzbgKZqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 머신 러닝이란\n",
        "머신 러닝은 크게 학습 단계, 예측 단계로 구분.\n",
        "훈련 데이터를 머신 러닝 알고리즘에 적용해 학습시키고, 이 학습 결과로 모형이 생성. 예측 단계에서는 학습 단계에서 생성된 모형에 새로운 데이터를 적용해 결과를 예측\n",
        "\n",
        "주요 구성 요소: 데이터, 모델(모형)\n",
        "1. 데이터: 머신 러닝이 학습 모델을 만드는 데 사용하는 것, 실제 데이터 특징이 잘 반영되고 편향되지 않는 훈련 데이터 확보하는 것이 중요\n",
        "2. 모델: 머신 러닝의 학습 단계에서 얻은 최종 결과물로 가설이라고도 함.\n",
        "- 모델(가설) 선택\n",
        "- 모델 학습 및 평가\n",
        "- 평가를 바탕으로 모델 업데이트"
      ],
      "metadata": {
        "id": "tayanE4vK_Vp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 머신 러닝 학습 알고리즘\n",
        "지도 학습, 비지도 학습, 강화 학습\n",
        "1. 지도 학습: 정답이 무엇인지 컴퓨터에 알려 주고 학습시키는 방법\n",
        "- 분류, 회귀\n",
        "2. 비지도 학습: 정답을 알려주지 않고 특징이 비슷한 데이터를 클러스터링(범주화)하여 예측하는 학습 방법\n",
        "- 군집, 차원 축소\n",
        "3. 강화 학습: 자신의 행동에 대한 보상을 받으며 학습을 진행"
      ],
      "metadata": {
        "id": "BNCEhwcHLyZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 딥러닝이란\n",
        "- 딥러닝이 머신 러닝과 다른 큰 차이점은 인간의 뇌를 기초로 해 설계했다는 것\n",
        "- 컴퓨터에 뉴런과 시냅스 개념을 적용\n",
        "- 복잡하게 연결된 수많은 뉴런을 병렬 연산해 기존에 컴퓨터가 수행하지 못했던 음성/영상 인식 등 처리를 가능하게 함\n",
        "\n",
        "### 1.3.1 딥러닝 학습 과정\n",
        "1. 데이터 준비\n",
        "2. 모델 정의\n",
        "- 은닉층 개수가 많을수록 성능이 좋아지지만 과적합이 발생할 확률이 높음\n",
        "3. 모델 컴파일\n",
        "- 활성화 함수, 옵티마이저, 손실 함수 선택\n",
        "- 훈련 데이터셋 형태가 연속형(MSE), 이진 분류(Cross Entropy)\n",
        "4. 모델 훈련\n",
        "- 전체 훈련 데이터셋에서 일정한 묶음으로 나누어 처리할 수 있는 배치와 훈련의 횟수인 에포크 선택이 중요\n",
        "5. 모델 예측\n",
        "- 예측력이 낮다면 파라미터 튜닝 or 신경망 자체를 재설계"
      ],
      "metadata": {
        "id": "0Utj0aSqMOgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.2 딥러닝 학습 알고리즘\n",
        "- 지도 학습, 비지도 학습, 전이 학습\n",
        "\n",
        "1. 지도 학습: 이미지 분류 - 합성곱 신경망(CNN)\n",
        "- 이미지 분류는 이미지를 알고리즘에 입력하면 그 이미지가 어떤 클래스에 속하는지 알려주기 때문에 이미지 데이터를 유사한 것끼리 분류할 때 사용\n",
        "- 이미지 인식은 사진을 분석해 그 안에 있는 사물의 종류를 인식하는 것\n",
        "- 이미지 분할은 영상에서 사물이나 배경 등 객체 간 영역을 픽셀 단위로 구분하는 기술(X-ray, CT, MRI)\n",
        "- 시계열 데이터 분류 - 순환 신경망(RNN)\n",
        "\n",
        "2. 비지도 학습 - 워드 임베딩과 군집\n",
        "- 워드 임베딩: 단어를 벡터로 표현\n",
        "- 군집: 아무런 정보가 없는 상태에서 데이터를 분류하는 방법\n",
        "\n",
        "3. 전이 학습: 사전에 학습이 완료된 모델을 가지고 우리가 원하는 학습에 미세 조정 기법을 이용해 학습시키는 방법"
      ],
      "metadata": {
        "id": "Oh9BqxxpNyaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2장. 실습 환경 설정과 파이토치 기초\n",
        "## 2.1 파이토치 개요\n",
        "파이토치는 딥러닝 프레임워크로 루아 언어로 개발되었떤 토치를 파이썬 버전으로 내놓은 것\n",
        "\n",
        "대상\n",
        "- 넘파이를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
        "- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우\n",
        "\n",
        "### 2.1.1 파이토치 특징 및 장점\n",
        "\"GPU에서 텐서 조작 및 동적 신경망 구축이 가능한 프레임워크\"\n",
        "- GPU: 연산 속도를 빠르게 하는 역할\n",
        "- 텐서: 파치토치의 데이터 형태, 단일 데이터 형식으로 된 자료들의 다차원 행렬, 간단한 명령어 사용해 GPU로 연산 수행\n",
        "- 동적 신경망: 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망, 예를 들어 학습 중에 은닉층을 추가하거나 제거하는 등 모델의 네트워크 조작이 가능\n",
        "\n",
        "장점: 단순함, 성능(낮은 CPU 활용), 직관적인 인터페이스\n",
        "\n",
        "### 2.1.2 파이토치의 아키텍처\n",
        "파이토치 API - 파이토치 엔진 - 연산 처리\n",
        "1. 파이토치 API: 사용자가 이해하기 쉬운 API를 제공해 텐서에 대한 처리와 신경망을 구축하고 훈련할 수 있도록 도움\n",
        "- torch: GPU를 지원하는 텐서 패키지\n",
        "- torch.autograd: 자동 미분 패키지\n",
        "- torch.nn: 신경망 구축 및 훈련 패키지\n",
        "- torch.multiprocessing: 파이썬 멀티프로세싱 패키지\n",
        "- torch.utils: DataLoader 및 기타 유틸리티 제공하는 패키지"
      ],
      "metadata": {
        "id": "1z4qToEuPYgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 파이토치 기초 문법\n",
        "### 2.2.1 텐서 다루기\n",
        "탠서 생성 및 변환"
      ],
      "metadata": {
        "id": "Mug0yoOYRbbU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MS87zzZKMWn",
        "outputId": "391b17fa-4ef0-4ce5-a92c-2b7f13c179b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0')\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.tensor([[1,2],[3,4]]))\n",
        "print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\"))\n",
        "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2],[3,4]])\n",
        "print(temp.numpy())\n",
        "\n",
        "temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")\n",
        "print(temp.to(\"cpu\").numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBzT4176RvZd",
        "outputId": "f57c52fe-5159-4871-ef38-d3a675ea8e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 인덱스 조작\n",
        "- torch.FloatTensor: 32비트의 부동 소수점\n",
        "- torch.DoubleTensor: 64비트의 부동 소수점\n",
        "- torch.LongTensor: 64비트의 부호가 있는 정수"
      ],
      "metadata": {
        "id": "rZscdobtSb6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.FloatTensor([1,2,3,4,5,6,7])\n",
        "print(temp[0], temp[1], temp[-1])\n",
        "print('------------------')\n",
        "print(temp[2:5], temp[4:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyrsUu9gSZk4",
        "outputId": "bba36659-c149-4850-f023-da728a1cd26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "------------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 연산 및 차원 조작\n",
        "v = torch.tensor([1,2,3])\n",
        "w = torch.tensor([3,4,6])\n",
        "print(w-v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDG6iNm8Su5X",
        "outputId": "a3f0ff92-8aa3-489f-e1b6-5be64e820982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 차원 조작\n",
        "temp = torch.tensor([\n",
        "    [1,2],[3,4]])\n",
        "\n",
        "print(temp.shape)\n",
        "print('-------------------')\n",
        "print(temp.view(4,1))\n",
        "print('-------------------')\n",
        "print(temp.view(-1))\n",
        "print('-------------------')\n",
        "print(temp.view(1,-1))\n",
        "print('-------------------')\n",
        "print(temp.view(-1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JR-956jS6Bj",
        "outputId": "de7ca0d3-069e-4276-c997-85158e4f5287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "-------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "-------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "-------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "-------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 데이터 준비\n",
        "- 데이터 호출: 파이썬 라이브러리, 파이토치에서 제공하는 데이터 이용\n",
        "- 데이터가 이미지일 경우 분산된 파일에서 데이터 읽은 후 전처리 하고 배치 단위로 분할해 처리\n",
        "- 데이터가 텍스트일 경우 임베딩 과정을 거쳐 서로 다른 길이의 시퀀스를 배치 단위로 분할해 처리"
      ],
      "metadata": {
        "id": "SlxYGf1jTPhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQE308IuTOHe",
        "outputId": "9da45f9a-e677-45a9-a001-170cff1a6580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "data = pd.read_csv('../class2.csv')\n",
        "\n",
        "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
        "y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()"
      ],
      "metadata": {
        "id": "IH_q4_KITfXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "커스텀 데이터셋을 만들어 사용\n",
        "- 딥러닝은 기본적으로 대량의 데이터를 이용해 모델을 학습시킴\n",
        "- 데이터를 한 번에 다 부르지 않고 조금씩 나누어 불러서 사용하는 방식이 커스템 데이터셋"
      ],
      "metadata": {
        "id": "UvVqD6SDT6VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "  def __len__(self):\n",
        "  def __getitem__(self, index):"
      ],
      "metadata": {
        "id": "B1GLhWmDUDD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "tnvQ8HmpUOaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    self.label = pd.read_csv(csv_file)\n",
        "\n",
        "  def __init__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
        "    label = torch.tensor(self.label.iloc[idx,3]).int()\n",
        "    return sample, label\n",
        "\n",
        "tensor_dataset = CustomDataset('../covtype.csv')\n",
        "dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "agvLufUuUUJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(dataset,0):\n",
        "  print(i, end='')\n",
        "  batch=data[0]\n",
        "  print(barch.size())"
      ],
      "metadata": {
        "id": "cNGypuQOU7K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치에서 제공하는 데이터셋 사용\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QUkz7LbVFl8",
        "outputId": "33b6a50c-4054-4558-d77e-8f150cd783d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transform as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transform.ToTenser(),\n",
        "    transform.Normalize((0.5,), (1.0,))\n",
        "])\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import requests\n",
        "download_root = '../chap02/data/MNIST_DATASET'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True,\n",
        "                      download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False,\n",
        "                      download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False,\n",
        "                      download=True)"
      ],
      "metadata": {
        "id": "fINuyu7eVJed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 모델 정의\n",
        "모듈에 상속한 클래스를 사용\n",
        "- 계층(layer): 모듈 또는 모듈을 구성하는 한 개의 계층으로 합성곱층, 선형계층 등이 존재\n",
        "- 모듈(module): 한 개 이상의 계층이 모여 구성된 것, 모듈이 모여 새로운 모듈을 만들 수도 있음.\n",
        "- 모델(model): 최종적으로 원하는 네트워크, 한 개의 모듈이 모델이 될 수 있음."
      ],
      "metadata": {
        "id": "pR0RQIzrR6hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순 신경망 정의\n",
        "model = nn.Linear(in_features=1, out_features=1, bias=True)\n",
        "\n",
        "# nn.Module()을 상속해 정의\n",
        "class MLP(Module):\n",
        "  def __init__(self, inputs):\n",
        "    super(MLP, self).__init__()\n",
        "    self.layer = Linear(inputs, 1)\n",
        "    self.activation = Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.layer(X)\n",
        "    X = self.activation(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "u8BXGmVPSLyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential 신경망 정의\n",
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.layer1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      x = self.layer3(x)\n",
        "      return x\n",
        "\n",
        "model = MLP()\n",
        "\n",
        "print(\"Printing children\\n----------------------\")\n",
        "print(list(model.children()))\n",
        "print(\"\\n\\nPrinting Modules\\n-----------------------\")\n",
        "print(list(model.modules()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBWgOBpUSmtp",
        "outputId": "45ac7a7b-89dc-4104-a04d-7ec0ced2d078"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing children\n",
            "----------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            ")]\n",
            "\n",
            "\n",
            "Printing Modules\n",
            "-----------------------\n",
            "[MLP(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "), Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential은 모델 계층이 복잡할수록 효과가 뛰어남."
      ],
      "metadata": {
        "id": "MrOkJdIUUKLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수로 신경망을 정의\n",
        "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
        "  hidden = nn.Linear(n_features=in_features, out_features=hidden_features,\n",
        "                     bias=True)\n",
        "  activation = nn.ReLU()\n",
        "  output = nn.Linear(in_features=hidden_features, out_features=out_features,\n",
        "                     bias=True)\n",
        "  net = nn.Sequential(hidden, activation, output)\n",
        "  return net"
      ],
      "metadata": {
        "id": "DlpBS4eNT9E8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.4 모델의 파라미터 정의\n",
        "- 손실 함수(loss funtion): 학습하는 동안 출력과 실제 값 사이의 오차 측정\n",
        "  - BCELoss: 이진 분류를 위해 사용\n",
        "  - CrossEntropyLoss: 다중 클래스 분류를 위해 사용\n",
        "  - MSELoss: 회귀 모델에서 사용\n",
        "- 옵티마이저(optimizer): 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법 결정\n",
        "  - step() 메서드 통해 전달받은 파라미터를 업데이트\n",
        "  - 모델의 파라미터별로 다른 기준을 적용 가능\n",
        "  - torch.optim.Optimizer(params, defaults)는 모든 옵티마이저의 기본이 되는 클래스\n",
        "  - zero_grad() 메서드는 옵티마이저에 사용된 파라미터들의 기울기를 0으로 만듦\n",
        "  - torch.optim.lr_scheduler는 에포크에 따라 학습률을 조절 가능\n",
        "- 학습률 스케쥴러: 미리 지정한 횟수의 에포크를 지날 때마다 학습률을 감소시켜 줌.\n",
        "  - optim.lr_scheduler.LambdaLR: 람다 함수를 이용해 그 함수의 결과를 학습률로 설정\n",
        "  - optim.lr_scheduler.StepLR: 특정 단계마다 학습률을 감마 비율만틈 감소시킴\n",
        "  - optim.lr_scheduler.MultiStepLR: StepLR과 비슷하지만 특정 단계가 아닌 지정된 에포크에만 감마 비율로 감소시킴\n",
        "  - optim.lr_scheduler.ExponenitalLR: 에포크마다 이전 학습률에 감마만틈 곱함.\n",
        "  - optim.lr_scheduler.CosineAnnealingLR: 학습률을 코사인 함수의 형태처럼 변화시킴.\n",
        "  - optim.lr_scheduler.ReduceLROnPlateau: 학습이 잘되고 있는지 아닌지를 동적으로 학습률을 변화시킬 수 있음.\n",
        "- 지표: 훈련가 테스트 단계를 모니터링함."
      ],
      "metadata": {
        "id": "CZXYGWDkUqjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "                                              lr_lambda=lambda epoch: 0.95 ** epoch)\n",
        "for epoch in range(1, 100+1):\n",
        "  for x, y in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "loss_fn(model(x), y).backward()\n",
        "optimizer.step()\n",
        "scheduler.step()"
      ],
      "metadata": {
        "id": "qEzPd6pUUpoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.5 모델 훈련\n",
        "학습시킨다는 것은 y=wx+b라는 함수에서 w와 b의 적절한 값을 찾는다는 의미\n",
        "\n",
        "훈련 방법\n",
        "1. optimizer.zero_grad() 메서드를 이용해 기울기를 초기화\n",
        "2. loss.backward() 메서드를 이용해 기울기를 자동 계산."
      ],
      "metadata": {
        "id": "JghryNO6WaE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  yhat = model(x_train)\n",
        "  loss = criterion(yhat, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "85len2mtWzVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.6 모델 평가\n",
        "- 함수와 모듈을 이용하는 두 가지 방법이 있음."
      ],
      "metadata": {
        "id": "OFvCmGAJW8eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poSEMWpDXIsf",
        "outputId": "0138af48-6925-4054-f45e-1101ecf74b2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "preds = torch.randn(10,5).softmax(dim=-1)\n",
        "target = tarch.randint(5, (10,))\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(preds,target)\n",
        "\n",
        "metrics = torchmetrics.Accuracy()\n",
        "\n",
        "n_batches = 10\n",
        "for i in range(n_batches):\n",
        "  preds = torch.randn(10,5).softmax(dim=-1)\n",
        "  target = torch.randint(5,(10,))\n",
        "\n",
        "  acc = metrics(preds, target)\n",
        "  print(f\"Accuracy on batch {i}: {acc}\")\n",
        "\n",
        "acc = metric.compute()\n",
        "print(f\"Accuracy on all data: {acc}\")"
      ],
      "metadata": {
        "id": "e9Bo8R-LXMkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.7 훈련 과정 모니터링\n",
        "텐서보드를 이용하면 학습에 사용되는 각종 파라미터 값이 어떻게 변화하는지 손쉽게 시각화 가능\n",
        "1. 텐서보드를 설정\n",
        "2. 텐서보드에 기록\n",
        "3. 텐서보드를 사용해 모델 구조 살펴봄"
      ],
      "metadata": {
        "id": "Wz93O8UHXvLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFeH64eRdPr_",
        "outputId": "68209689-ac98-48b6-f992-f76aebe5a4b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('../chap02/tensorboard')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  batch_loss = 0.0\n",
        "\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    x, y = x.to(device).float(), y.to(device).float()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    writer.add_scalar(\"Loss\", loss, epoch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "zKlADBfcdTDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard --logdir=../chap02/tensorboard --port=6006"
      ],
      "metadata": {
        "id": "InkWR5ckd6-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}